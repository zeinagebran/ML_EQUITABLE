{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "\n",
    "class ConnectomeTokenizer(nn.Module):\n",
    "    def __init__(self, in_channels=32, hidden_dim=64, out_dim=128):\n",
    "        super(ConnectomeTokenizer, self).__init__()\n",
    "\n",
    "        nn1 = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        self.gnn = GINEConv(nn1, edge_dim=1)\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, list_of_graph_lists):\n",
    "        \"\"\"\n",
    "        list_of_graph_lists: List of size [B], each element is a list of 9 PyG graphs (one per band)\n",
    "        Returns: token_tensor of shape [B, 9, out_dim]\n",
    "        \"\"\"\n",
    "        batch_size = len(list_of_graph_lists)\n",
    "        all_tokens = []\n",
    "\n",
    "        for graphs_per_sample in list_of_graph_lists:\n",
    "            sample_tokens = []\n",
    "            for g in graphs_per_sample:\n",
    "                # Make batch dimension to use PyG\n",
    "                g.batch = torch.zeros(g.x.size(0), dtype=torch.long)  # 1 sample = 1 graph\n",
    "                x = self.gnn(g.x, g.edge_index, g.edge_attr) ## [N, out_dim] , N is the number of nodes in the graph.\n",
    "                token = global_mean_pool(x, g.batch)  # Shape: [1, out_dim]\n",
    "                sample_tokens.append(token)\n",
    "\n",
    "            # Shape: [9, out_dim]\n",
    "            sample_tokens = torch.cat(sample_tokens, dim=0).unsqueeze(0)  # Add batch dim\n",
    "            all_tokens.append(sample_tokens)\n",
    "\n",
    "        # Shape: [B, 9, out_dim]\n",
    "        token_tensor = torch.cat(all_tokens, dim=0)\n",
    "        return token_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16263ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token shape: torch.Size([2, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Simulate 1 graph (19 nodes, features = 32)\n",
    "def make_dummy_graph():\n",
    "    x = torch.randn(19, 32)\n",
    "    edge_index = torch.randint(0, 19, (2, 50)) ###Randomly connects 50 pairs of nodes\n",
    "    edge_attr = torch.rand(50, 1)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# simulate one batch of 2 samples Ã— 9 graphs each\n",
    "batch_graphs = [\n",
    "    [make_dummy_graph() for _ in range(9)],\n",
    "    [make_dummy_graph() for _ in range(9)]\n",
    "]\n",
    "\n",
    "# Create and test the tokenizer\n",
    "model = ConnectomeTokenizer(in_channels=32, hidden_dim=64, out_dim=128)\n",
    "tokens = model(batch_graphs)  # it should be [2, 9, 128] because 2=B(nb of batches), 9=nb graphs per sample, 128=dimension of token representation\n",
    "print(\"Token shape:\", tokens.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53b8dc",
   "metadata": {},
   "source": [
    "What it does:\n",
    "Processes a batch of graphs (one graph per frequency band) and generates one token per graph.\n",
    "\n",
    "Each token is a fixed-size vector ([out_dim]) that represents the graph-level embedding.\n",
    "\n",
    "Input: A batch of graphs (e.g., [B, 9, graphs]).\n",
    "\n",
    "Output: A tensor of shape [B, 9, D], where each token corresponds to a frequency band."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48e5b2",
   "metadata": {},
   "source": [
    "this is a dummy test, once the pre process is done (real data converted to 9 connectomes), we can replace the dummy graphs in this test with the actual graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
